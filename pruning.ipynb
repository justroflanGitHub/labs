{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RuBERT Pruning"
      ],
      "metadata": {
        "id": "Jt8va5P-CgVt"
      },
      "id": "Jt8va5P-CgVt"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install textpruner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDBkRvrWkdCR",
        "outputId": "cbf55002-0e60-48c1-c763-9be7c006d580"
      },
      "id": "zDBkRvrWkdCR",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting textpruner\n",
            "  Downloading textpruner-1.1.post2.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.0 in /usr/local/lib/python3.11/dist-packages (from textpruner) (4.50.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from textpruner) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from textpruner) (4.67.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from textpruner) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from textpruner) (5.29.4)\n",
            "Collecting numpy<1.22 (from textpruner)\n",
            "  Downloading numpy-1.21.1.zip (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (2024.12.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7->textpruner)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->textpruner) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7->textpruner) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0->textpruner) (0.29.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0->textpruner) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0->textpruner) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0->textpruner) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0->textpruner) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0->textpruner) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0->textpruner) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7->textpruner) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.0->textpruner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.0->textpruner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.0->textpruner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.0->textpruner) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: textpruner, numpy\n",
            "  Building wheel for textpruner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textpruner: filename=textpruner-1.1.post2-py3-none-any.whl size=43878 sha256=bfca39d852311149fcf2ab8068f9d72e81db595e323a81bf625733b2b3a6422f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/96/c7/86873729b6f3453a532aaee5f3b472a1353317016a532309f9\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for numpy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully built textpruner\n",
            "Failed to build numpy\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (numpy)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4a5cd210-33ba-47c5-ac4f-cab5f606c168",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:21:45.931516Z",
          "iopub.status.busy": "2023-09-24T19:21:45.931107Z",
          "iopub.status.idle": "2023-09-24T19:21:52.564178Z",
          "shell.execute_reply": "2023-09-24T19:21:52.563371Z",
          "shell.execute_reply.started": "2023-09-24T19:21:45.931486Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "4a5cd210-33ba-47c5-ac4f-cab5f606c168",
        "outputId": "ff0a7908-9efa-4e80-ba5e-1e815aca0d44"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'PyTorchBenchmark' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-af55ed7c4e79>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTorchBenchmark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyTorchBenchmarkArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'PyTorchBenchmark' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "310c1576-86c0-4ca6-afb3-ef360cfac5af",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T17:29:28.868265Z",
          "iopub.status.busy": "2023-09-24T17:29:28.866915Z",
          "iopub.status.idle": "2023-09-24T17:29:29.296308Z",
          "shell.execute_reply": "2023-09-24T17:29:29.295323Z",
          "shell.execute_reply.started": "2023-09-24T17:29:28.868219Z"
        },
        "colab": {
          "referenced_widgets": [
            "bf99428881ac4ffbbc20128c4a7a85e7"
          ]
        },
        "id": "310c1576-86c0-4ca6-afb3-ef360cfac5af",
        "outputId": "c423b81f-ccbd-4b36-a15d-f781b7db7d04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration Den4ikAI--russian_dialogues-2f0e674e933ff89a\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/Den4ikAI___json/Den4ikAI--russian_dialogues-2f0e674e933ff89a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf99428881ac4ffbbc20128c4a7a85e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset('Den4ikAI/russian_dialogues')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da5a49e2-3c22-40ff-a2a5-70678975f3fb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T17:29:33.950207Z",
          "iopub.status.busy": "2023-09-24T17:29:33.949768Z",
          "iopub.status.idle": "2023-09-24T17:29:34.518146Z",
          "shell.execute_reply": "2023-09-24T17:29:34.517055Z",
          "shell.execute_reply.started": "2023-09-24T17:29:33.950179Z"
        },
        "id": "da5a49e2-3c22-40ff-a2a5-70678975f3fb",
        "outputId": "d60b6a6b-b849-4823-afb2-b74a53d2046d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/Den4ikAI___json/Den4ikAI--russian_dialogues-2f0e674e933ff89a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-ecba1f789bb6e582.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/Den4ikAI___json/Den4ikAI--russian_dialogues-2f0e674e933ff89a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-5fc2dd5f7c22d453.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/Den4ikAI___json/Den4ikAI--russian_dialogues-2f0e674e933ff89a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-928b7c7c52b925b5.arrow\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.class_encode_column('relevance')\n",
        "dataset = dataset.rename_column('relevance', 'labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0258bfb-7369-42ba-83ab-3a619dbb0ca0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T17:29:37.990729Z",
          "iopub.status.busy": "2023-09-24T17:29:37.990315Z",
          "iopub.status.idle": "2023-09-24T17:29:41.077627Z",
          "shell.execute_reply": "2023-09-24T17:29:41.076484Z",
          "shell.execute_reply.started": "2023-09-24T17:29:37.990702Z"
        },
        "id": "c0258bfb-7369-42ba-83ab-3a619dbb0ca0"
      },
      "outputs": [],
      "source": [
        "dataset = dataset['train'].train_test_split(\n",
        "    test_size=0.05,\n",
        "    shuffle=True,\n",
        "    stratify_by_column='labels',\n",
        "    seed=42\n",
        "    )\n",
        "\n",
        "dataset = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5140729-440a-4317-83ec-b20a98d05a7b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T17:29:43.346495Z",
          "iopub.status.busy": "2023-09-24T17:29:43.345948Z",
          "iopub.status.idle": "2023-09-24T17:29:46.609169Z",
          "shell.execute_reply": "2023-09-24T17:29:46.607711Z",
          "shell.execute_reply.started": "2023-09-24T17:29:43.346456Z"
        },
        "colab": {
          "referenced_widgets": [
            "eac620cfdfd643fb9da087954f9dca98"
          ]
        },
        "id": "b5140729-440a-4317-83ec-b20a98d05a7b",
        "outputId": "279538bc-e342-4a0c-8aa3-269b84ca2154"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eac620cfdfd643fb9da087954f9dca98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/124 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = dataset.filter(\n",
        "    lambda example: type(example['question']) is str and type(example['answer']) is str\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96099c22-b4fc-442f-890d-47582f1b7ad8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T17:29:46.676516Z",
          "iopub.status.busy": "2023-09-24T17:29:46.676168Z",
          "iopub.status.idle": "2023-09-24T17:29:49.920047Z",
          "shell.execute_reply": "2023-09-24T17:29:49.918688Z",
          "shell.execute_reply.started": "2023-09-24T17:29:46.676490Z"
        },
        "id": "96099c22-b4fc-442f-890d-47582f1b7ad8"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'Den4ikAI/ruBert-base-qa-ranker'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "\n",
        "print_size_of_model(model)"
      ],
      "metadata": {
        "id": "5pKKFhbUliTh"
      },
      "id": "5pKKFhbUliTh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee458ef-04c7-4227-964d-9317423b1d21",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T17:29:49.922454Z",
          "iopub.status.busy": "2023-09-24T17:29:49.922051Z",
          "iopub.status.idle": "2023-09-24T17:29:50.124570Z",
          "shell.execute_reply": "2023-09-24T17:29:50.123440Z",
          "shell.execute_reply.started": "2023-09-24T17:29:49.922397Z"
        },
        "id": "4ee458ef-04c7-4227-964d-9317423b1d21",
        "outputId": "ab1fdaa3-5c4d-4516-b4af-7875f599377d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    model.to('cuda')\n",
        "print(model.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd44446d-50bb-408d-90c5-a8adef8251f5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T17:29:54.749449Z",
          "iopub.status.busy": "2023-09-24T17:29:54.748718Z",
          "iopub.status.idle": "2023-09-24T17:29:54.756005Z",
          "shell.execute_reply": "2023-09-24T17:29:54.754724Z",
          "shell.execute_reply.started": "2023-09-24T17:29:54.749409Z"
        },
        "id": "fd44446d-50bb-408d-90c5-a8adef8251f5"
      },
      "outputs": [],
      "source": [
        "def tokenization(example):\n",
        "    return tokenizer(\n",
        "        '[CLS]' + example['question'] + '[RESPONSE_TOKEN]' + example['answer'],\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        add_special_tokens=False\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf97d650-e139-4e96-885a-9b0188d1fbab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:08:36.180081Z",
          "iopub.status.busy": "2023-09-24T18:08:36.179734Z",
          "iopub.status.idle": "2023-09-24T18:08:36.222512Z",
          "shell.execute_reply": "2023-09-24T18:08:36.221482Z",
          "shell.execute_reply.started": "2023-09-24T18:08:36.180055Z"
        },
        "id": "bf97d650-e139-4e96-885a-9b0188d1fbab"
      },
      "outputs": [],
      "source": [
        "dataset_test = dataset.select(indices=range(5000))\n",
        "dataset_pruning = dataset.select(indices=range(5000, 15000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c97598-6516-493d-ab44-e6515cd483bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:09:02.813110Z",
          "iopub.status.busy": "2023-09-24T18:09:02.812727Z",
          "iopub.status.idle": "2023-09-24T18:09:13.203511Z",
          "shell.execute_reply": "2023-09-24T18:09:13.202492Z",
          "shell.execute_reply.started": "2023-09-24T18:09:02.813083Z"
        },
        "colab": {
          "referenced_widgets": [
            "0ac224d0840e4ba2b806cc1f901c10ad",
            "6190bfcee69a4111aa5c0c32d97a1194"
          ]
        },
        "id": "08c97598-6516-493d-ab44-e6515cd483bf",
        "outputId": "63b2b931-e826-4dd4-9eca-59e675c48a6c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ac224d0840e4ba2b806cc1f901c10ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6190bfcee69a4111aa5c0c32d97a1194",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_test = dataset_test.map(tokenization, batched=False)\n",
        "dataset_pruning = dataset_pruning.map(tokenization, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b456c69a-941e-4cfd-a669-243e4b4bc4df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:09:41.961079Z",
          "iopub.status.busy": "2023-09-24T18:09:41.960659Z",
          "iopub.status.idle": "2023-09-24T18:09:41.968559Z",
          "shell.execute_reply": "2023-09-24T18:09:41.967254Z",
          "shell.execute_reply.started": "2023-09-24T18:09:41.961051Z"
        },
        "id": "b456c69a-941e-4cfd-a669-243e4b4bc4df"
      },
      "outputs": [],
      "source": [
        "dataset_test.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
        ")\n",
        "\n",
        "dataset_pruning.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec014c5-9ca1-4732-a311-5daa411890be",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:09:43.767468Z",
          "iopub.status.busy": "2023-09-24T18:09:43.767036Z",
          "iopub.status.idle": "2023-09-24T18:09:43.771812Z",
          "shell.execute_reply": "2023-09-24T18:09:43.770926Z",
          "shell.execute_reply.started": "2023-09-24T18:09:43.767440Z"
        },
        "id": "cec014c5-9ca1-4732-a311-5daa411890be"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4017ce0-9fe2-4065-a177-c806b753a332",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:13:55.594080Z",
          "iopub.status.busy": "2023-09-24T18:13:55.593157Z",
          "iopub.status.idle": "2023-09-24T18:13:55.598708Z",
          "shell.execute_reply": "2023-09-24T18:13:55.597520Z",
          "shell.execute_reply.started": "2023-09-24T18:13:55.594052Z"
        },
        "id": "e4017ce0-9fe2-4065-a177-c806b753a332"
      },
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eec253e-1916-48ff-96d8-a3c71458567a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:13:58.513819Z",
          "iopub.status.busy": "2023-09-24T18:13:58.513316Z",
          "iopub.status.idle": "2023-09-24T18:13:58.521016Z",
          "shell.execute_reply": "2023-09-24T18:13:58.519490Z",
          "shell.execute_reply.started": "2023-09-24T18:13:58.513783Z"
        },
        "id": "4eec253e-1916-48ff-96d8-a3c71458567a"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "pruning_dataloader = DataLoader(\n",
        "    dataset_pruning,\n",
        "    batch_size=batch_size,\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2204e44-e70f-449a-a20a-cfdf9cfaa7aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:13:54.970169Z",
          "iopub.status.busy": "2023-09-24T19:13:54.968781Z",
          "iopub.status.idle": "2023-09-24T19:13:54.981126Z",
          "shell.execute_reply": "2023-09-24T19:13:54.979964Z",
          "shell.execute_reply.started": "2023-09-24T19:13:54.970116Z"
        },
        "id": "d2204e44-e70f-449a-a20a-cfdf9cfaa7aa"
      },
      "outputs": [],
      "source": [
        "def predict_with_model(model, dataloader, max_idx=None):\n",
        "    preds = []\n",
        "    facts = []\n",
        "\n",
        "    for idx, batch in tqdm(enumerate(dataloader), total=max_idx if max_idx else len(dataloader)):\n",
        "        facts.append(batch.labels.cpu().numpy())\n",
        "        batch = batch.to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(\n",
        "                input_ids=batch.input_ids,\n",
        "                attention_mask=batch.attention_mask,\n",
        "                token_type_ids=batch.token_type_ids\n",
        "            )\n",
        "        preds.append(torch.sigmoid(pred.logits).cpu().numpy())\n",
        "\n",
        "        if idx == max_idx:\n",
        "            break\n",
        "\n",
        "    facts = np.concatenate(facts)\n",
        "    preds = np.concatenate(preds)\n",
        "\n",
        "    return facts, preds\n",
        "\n",
        "\n",
        "def evaluate_model(model, dev_dataloader):\n",
        "    facts, preds = predict_with_model(model, dev_dataloader)\n",
        "    roc_score = roc_auc_score(facts, preds[:, 0])\n",
        "    return roc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d3ba0d-b861-43a8-acb6-768449219b4d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T00:06:47.100013Z",
          "iopub.status.busy": "2023-09-24T00:06:47.099483Z",
          "iopub.status.idle": "2023-09-24T00:10:15.068228Z",
          "shell.execute_reply": "2023-09-24T00:10:15.067185Z",
          "shell.execute_reply.started": "2023-09-24T00:06:47.099972Z"
        },
        "colab": {
          "referenced_widgets": [
            "2e872c2acf1d4c969882b9991f2c10f7"
          ]
        },
        "id": "e7d3ba0d-b861-43a8-acb6-768449219b4d",
        "outputId": "65685c82-6bd2-4923-f6e5-ef660ec8e7bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e872c2acf1d4c969882b9991f2c10f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "roc_auc_score = evaluate_model(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98315577-63c8-4733-ac1c-b6d16f308898",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T00:10:15.073724Z",
          "iopub.status.busy": "2023-09-24T00:10:15.073497Z",
          "iopub.status.idle": "2023-09-24T00:10:15.078667Z",
          "shell.execute_reply": "2023-09-24T00:10:15.077680Z",
          "shell.execute_reply.started": "2023-09-24T00:10:15.073698Z"
        },
        "id": "98315577-63c8-4733-ac1c-b6d16f308898",
        "outputId": "be9cf949-32eb-4c05-c721-bad6512e3f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Area Under ROC Curve is 0.9695577994975315 before quantization\n"
          ]
        }
      ],
      "source": [
        "print(f'Dev Area Under ROC Curve is {roc_auc_score} before quantization')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "718d0148-f4d5-4da9-ba0a-9717b4a784a5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T00:10:15.082839Z",
          "iopub.status.busy": "2023-09-24T00:10:15.082614Z",
          "iopub.status.idle": "2023-09-24T00:10:15.140902Z",
          "shell.execute_reply": "2023-09-24T00:10:15.139930Z",
          "shell.execute_reply.started": "2023-09-24T00:10:15.082815Z"
        },
        "id": "718d0148-f4d5-4da9-ba0a-9717b4a784a5"
      },
      "outputs": [],
      "source": [
        "benchmark_args = PyTorchBenchmarkArguments(\n",
        "    models=[MODEL_NAME],\n",
        "    training=False,\n",
        "    inference=True,\n",
        "    sequence_lengths=[8,128,256,512],\n",
        "    batch_sizes=[1,32,64],\n",
        "    multi_process=False,\n",
        "    cuda=True,\n",
        "    speed=True,\n",
        ")\n",
        "\n",
        "benchmark = PyTorchBenchmark(benchmark_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d82589-ff06-4131-b15b-43086bca05b4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:20:38.788733Z",
          "iopub.status.busy": "2023-09-24T19:20:38.788356Z",
          "iopub.status.idle": "2023-09-24T19:20:44.041142Z",
          "shell.execute_reply": "2023-09-24T19:20:44.039417Z",
          "shell.execute_reply.started": "2023-09-24T19:20:38.788691Z"
        },
        "id": "84d82589-ff06-4131-b15b-43086bca05b4",
        "outputId": "03f0e218-1137-4f81-91ee-57d6804ad7f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Requirement already satisfied: py3nvml in /usr/local/lib/python3.9/dist-packages (0.2.7)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.9/dist-packages (from py3nvml) (0.13.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install py3nvml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644377fb-76e9-492f-a2e9-7e52d31b623c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T00:10:15.144447Z",
          "iopub.status.busy": "2023-09-24T00:10:15.144190Z",
          "iopub.status.idle": "2023-09-24T00:15:06.140491Z",
          "shell.execute_reply": "2023-09-24T00:15:06.139418Z",
          "shell.execute_reply.started": "2023-09-24T00:10:15.144421Z"
        },
        "id": "644377fb-76e9-492f-a2e9-7e52d31b623c",
        "outputId": "8da6749f-6d45-4894-eacf-8ac6b993290b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 / 1\n",
            "\n",
            "====================       INFERENCE - SPEED - RESULT       ====================\n",
            "--------------------------------------------------------------------------------\n",
            "          Model Name             Batch Size     Seq Length     Time in s   \n",
            "--------------------------------------------------------------------------------\n",
            "Den4ikAI/ruBert-base-qa-ranker       1               8             0.009     \n",
            "Den4ikAI/ruBert-base-qa-ranker       1              128            0.009     \n",
            "Den4ikAI/ruBert-base-qa-ranker       1              256            0.011     \n",
            "Den4ikAI/ruBert-base-qa-ranker       1              512            0.019     \n",
            "Den4ikAI/ruBert-base-qa-ranker       32              8             0.011     \n",
            "Den4ikAI/ruBert-base-qa-ranker       32             128            0.135     \n",
            "Den4ikAI/ruBert-base-qa-ranker       32             256            0.365     \n",
            "Den4ikAI/ruBert-base-qa-ranker       32             512            0.765     \n",
            "Den4ikAI/ruBert-base-qa-ranker       64              8             0.018     \n",
            "Den4ikAI/ruBert-base-qa-ranker       64             128            0.349     \n",
            "Den4ikAI/ruBert-base-qa-ranker       64             256            0.709     \n",
            "Den4ikAI/ruBert-base-qa-ranker       64             512            1.578     \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====================      INFERENCE - MEMORY - RESULT       ====================\n",
            "--------------------------------------------------------------------------------\n",
            "          Model Name             Batch Size     Seq Length    Memory in MB \n",
            "--------------------------------------------------------------------------------\n",
            "Den4ikAI/ruBert-base-qa-ranker       1               8              3771     \n",
            "Den4ikAI/ruBert-base-qa-ranker       1              128             3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       1              256             3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       1              512             3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       32              8              3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       32             128             3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       32             256             3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       32             512             3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       64              8              3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       64             128             3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       64             256             3775     \n",
            "Den4ikAI/ruBert-base-qa-ranker       64             512             4543     \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "results = benchmark.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d7f164-c27c-4249-b024-d95d42d28141",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T17:25:26.221761Z",
          "iopub.status.busy": "2023-09-24T17:25:26.220610Z",
          "iopub.status.idle": "2023-09-24T17:25:32.211846Z",
          "shell.execute_reply": "2023-09-24T17:25:32.209868Z",
          "shell.execute_reply.started": "2023-09-24T17:25:26.221707Z"
        },
        "id": "c5d7f164-c27c-4249-b024-d95d42d28141",
        "outputId": "92e2c82c-0b73-4f7d-cd70-c6bbece8cd7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Collecting textpruner\n",
            "  Downloading textpruner-1.1.post2.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.0 in /usr/local/lib/python3.9/dist-packages (from textpruner) (4.21.3)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from textpruner) (1.12.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from textpruner) (4.64.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from textpruner) (0.1.97)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from textpruner) (3.19.6)\n",
            "Requirement already satisfied: numpy>1.17 in /usr/local/lib/python3.9/dist-packages (from textpruner) (1.23.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->textpruner) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (5.4.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (2.28.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (0.12.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers>=4.0->textpruner) (2.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.0->textpruner) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.0->textpruner) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers>=4.0->textpruner) (2019.11.28)\n",
            "Building wheels for collected packages: textpruner\n",
            "  Building wheel for textpruner (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for textpruner: filename=textpruner-1.1.post2-py3-none-any.whl size=43882 sha256=e862d3864095d3a7e9c6bbd52394634583335e362d16e3357c730291d2db6614\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/05/93/7ed7efba7071091691dd50709f6683955d609ff28324ac8710\n",
            "Successfully built textpruner\n",
            "Installing collected packages: textpruner\n",
            "Successfully installed textpruner-1.1.post2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install textpruner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a32434cd-e090-430a-bb22-c2989e8d6515",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:12:51.928333Z",
          "iopub.status.busy": "2023-09-24T18:12:51.927946Z",
          "iopub.status.idle": "2023-09-24T18:12:51.933803Z",
          "shell.execute_reply": "2023-09-24T18:12:51.932422Z",
          "shell.execute_reply.started": "2023-09-24T18:12:51.928305Z"
        },
        "id": "a32434cd-e090-430a-bb22-c2989e8d6515"
      },
      "outputs": [],
      "source": [
        "from textpruner import PipelinePruner, TransformerPruningConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356e38b4-d882-474d-9a08-8d3e111e9e1c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:14:03.473337Z",
          "iopub.status.busy": "2023-09-24T18:14:03.472799Z",
          "iopub.status.idle": "2023-09-24T18:14:03.480035Z",
          "shell.execute_reply": "2023-09-24T18:14:03.478604Z",
          "shell.execute_reply.started": "2023-09-24T18:14:03.473295Z"
        },
        "id": "356e38b4-d882-474d-9a08-8d3e111e9e1c"
      },
      "outputs": [],
      "source": [
        "transformer_pruning_config = TransformerPruningConfig(\n",
        "    target_ffn_size=2048,\n",
        "    target_num_of_heads=8,\n",
        "    pruning_method='iterative',\n",
        "    n_iters=4\n",
        ")\n",
        "\n",
        "pruner = PipelinePruner(model, tokenizer, transformer_pruning_config=transformer_pruning_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6eb2e2e-6254-44f3-841f-d14800f7bec8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T18:14:03.482157Z",
          "iopub.status.busy": "2023-09-24T18:14:03.481812Z",
          "iopub.status.idle": "2023-09-24T19:03:57.665133Z",
          "shell.execute_reply": "2023-09-24T19:03:57.663868Z",
          "shell.execute_reply.started": "2023-09-24T18:14:03.482130Z"
        },
        "id": "f6eb2e2e-6254-44f3-841f-d14800f7bec8",
        "outputId": "5a4e5770-8d55-4a23-a23b-25d1417f683f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating IS with loss: 100%|██████████| 1250/1250 [12:27<00:00,  1.67it/s]\n",
            "Calculating IS with loss: 100%|██████████| 1250/1250 [12:25<00:00,  1.68it/s]\n",
            "Calculating IS with loss: 100%|██████████| 1250/1250 [12:26<00:00,  1.67it/s]\n",
            "Calculating IS with loss: 100%|██████████| 1250/1250 [12:26<00:00,  1.67it/s]\n",
            "100%|██████████| 40000/40000 [00:05<00:00, 7662.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New embedding size 29613 pruned vocab file has been saved to ./pruned_models/pruned_V29613H8.0F2048/vocab.txt. Reintialize the tokenizer!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'./pruned_models/pruned_V29613H8.0F2048'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pruner.prune(dataloader=pruning_dataloader, dataiter=dataset['question'][5000:45000], save_model=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91ce89de-064c-4030-ab5c-b43a3a6545d7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:05:21.302050Z",
          "iopub.status.busy": "2023-09-24T19:05:21.301633Z",
          "iopub.status.idle": "2023-09-24T19:05:21.314124Z",
          "shell.execute_reply": "2023-09-24T19:05:21.312291Z",
          "shell.execute_reply.started": "2023-09-24T19:05:21.302023Z"
        },
        "collapsed": true,
        "id": "91ce89de-064c-4030-ab5c-b43a3a6545d7",
        "outputId": "86595f1a-ede7-4399-ed16-edcf018bc6d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"Den4ikAI/ruBert-base-qa-ranker\",\n",
              "  \"architectures\": [\n",
              "    \"BertForSequenceClassification\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"directionality\": \"bidi\",\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 2048,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_fc_size\": 768,\n",
              "  \"pooler_num_attention_heads\": 12,\n",
              "  \"pooler_num_fc_layers\": 3,\n",
              "  \"pooler_size_per_head\": 128,\n",
              "  \"pooler_type\": \"first_token_transform\",\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"problem_type\": \"single_label_classification\",\n",
              "  \"pruned_heads\": {\n",
              "    \"0\": [\n",
              "      1,\n",
              "      10,\n",
              "      4,\n",
              "      7\n",
              "    ],\n",
              "    \"1\": [\n",
              "      0,\n",
              "      9,\n",
              "      11,\n",
              "      6\n",
              "    ],\n",
              "    \"2\": [\n",
              "      0,\n",
              "      8,\n",
              "      10,\n",
              "      6\n",
              "    ],\n",
              "    \"3\": [\n",
              "      1,\n",
              "      10,\n",
              "      11,\n",
              "      6\n",
              "    ],\n",
              "    \"4\": [\n",
              "      8,\n",
              "      2,\n",
              "      3,\n",
              "      7\n",
              "    ],\n",
              "    \"5\": [\n",
              "      1,\n",
              "      10,\n",
              "      3,\n",
              "      9\n",
              "    ],\n",
              "    \"6\": [\n",
              "      9,\n",
              "      11,\n",
              "      5,\n",
              "      7\n",
              "    ],\n",
              "    \"7\": [\n",
              "      8,\n",
              "      11,\n",
              "      3,\n",
              "      6\n",
              "    ],\n",
              "    \"8\": [\n",
              "      0,\n",
              "      1,\n",
              "      3,\n",
              "      4\n",
              "    ],\n",
              "    \"9\": [\n",
              "      0,\n",
              "      1,\n",
              "      8,\n",
              "      7\n",
              "    ],\n",
              "    \"10\": [\n",
              "      0,\n",
              "      1,\n",
              "      10,\n",
              "      9\n",
              "    ],\n",
              "    \"11\": [\n",
              "      1,\n",
              "      2,\n",
              "      11,\n",
              "      7\n",
              "    ]\n",
              "  },\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.21.3\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 29613\n",
              "}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aa32425-5b20-4e27-a8c2-8c48c9c9e46f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:22:37.118187Z",
          "iopub.status.busy": "2023-09-24T19:22:37.117677Z",
          "iopub.status.idle": "2023-09-24T19:22:41.066030Z",
          "shell.execute_reply": "2023-09-24T19:22:41.064177Z",
          "shell.execute_reply.started": "2023-09-24T19:22:37.118148Z"
        },
        "id": "5aa32425-5b20-4e27-a8c2-8c48c9c9e46f"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = './pruned_models/pruned_V29613H8.0F2048/'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85bd0f2-b753-4364-9ffb-d3278bf7ddf9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:11:52.467540Z",
          "iopub.status.busy": "2023-09-24T19:11:52.466588Z",
          "iopub.status.idle": "2023-09-24T19:11:56.899137Z",
          "shell.execute_reply": "2023-09-24T19:11:56.897926Z",
          "shell.execute_reply.started": "2023-09-24T19:11:52.467497Z"
        },
        "colab": {
          "referenced_widgets": [
            "21a5633bf69e4949836d97ef21bd3163"
          ]
        },
        "id": "f85bd0f2-b753-4364-9ffb-d3278bf7ddf9",
        "outputId": "d6bf527e-77e9-4b3d-a5b8-90f22df10d73"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21a5633bf69e4949836d97ef21bd3163",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_test = dataset.select(indices=range(5000))\n",
        "dataset_test = dataset_test.map(tokenization, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e8294d3-1a93-47c6-b20f-75037a20cc0e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:12:08.873016Z",
          "iopub.status.busy": "2023-09-24T19:12:08.872658Z",
          "iopub.status.idle": "2023-09-24T19:12:08.879816Z",
          "shell.execute_reply": "2023-09-24T19:12:08.878078Z",
          "shell.execute_reply.started": "2023-09-24T19:12:08.872990Z"
        },
        "id": "2e8294d3-1a93-47c6-b20f-75037a20cc0e"
      },
      "outputs": [],
      "source": [
        "dataset_test.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "729541a6-a6d8-4534-9a33-97567c6e0d5c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:12:37.171879Z",
          "iopub.status.busy": "2023-09-24T19:12:37.171352Z",
          "iopub.status.idle": "2023-09-24T19:12:37.177279Z",
          "shell.execute_reply": "2023-09-24T19:12:37.176407Z",
          "shell.execute_reply.started": "2023-09-24T19:12:37.171839Z"
        },
        "id": "729541a6-a6d8-4534-9a33-97567c6e0d5c"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bbd95b2-acc5-4a84-9c9f-291619b15e9f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:12:50.188262Z",
          "iopub.status.busy": "2023-09-24T19:12:50.187298Z",
          "iopub.status.idle": "2023-09-24T19:12:50.196074Z",
          "shell.execute_reply": "2023-09-24T19:12:50.192911Z",
          "shell.execute_reply.started": "2023-09-24T19:12:50.188216Z"
        },
        "id": "8bbd95b2-acc5-4a84-9c9f-291619b15e9f"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4058bd3-9408-4cbd-bdde-837d9aa2fef7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:13:03.292954Z",
          "iopub.status.busy": "2023-09-24T19:13:03.292495Z",
          "iopub.status.idle": "2023-09-24T19:13:03.299795Z",
          "shell.execute_reply": "2023-09-24T19:13:03.297936Z",
          "shell.execute_reply.started": "2023-09-24T19:13:03.292918Z"
        },
        "id": "b4058bd3-9408-4cbd-bdde-837d9aa2fef7"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa56aaae-7669-48cb-8ebe-2d5a45867c60",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:14:00.678184Z",
          "iopub.status.busy": "2023-09-24T19:14:00.677451Z",
          "iopub.status.idle": "2023-09-24T19:15:47.345614Z",
          "shell.execute_reply": "2023-09-24T19:15:47.344106Z",
          "shell.execute_reply.started": "2023-09-24T19:14:00.678156Z"
        },
        "colab": {
          "referenced_widgets": [
            "6746ca3d6d194c5bbd4cbd295b3db868"
          ]
        },
        "id": "aa56aaae-7669-48cb-8ebe-2d5a45867c60",
        "outputId": "bf7cb300-ecd0-4b40-b2a3-1099dde9c3a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6746ca3d6d194c5bbd4cbd295b3db868",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "roc_auc_score = evaluate_model(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "915e04f4-f046-4bab-a737-04958498a8d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:16:29.476706Z",
          "iopub.status.busy": "2023-09-24T19:16:29.476119Z",
          "iopub.status.idle": "2023-09-24T19:16:29.484202Z",
          "shell.execute_reply": "2023-09-24T19:16:29.483125Z",
          "shell.execute_reply.started": "2023-09-24T19:16:29.476663Z"
        },
        "id": "915e04f4-f046-4bab-a737-04958498a8d4",
        "outputId": "f764b53a-100a-4d23-ea66-68a34bf23b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Area Under ROC Curve is 0.8927088349674912 after pruning\n"
          ]
        }
      ],
      "source": [
        "print(f'Dev Area Under ROC Curve is {roc_auc_score} after pruning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93b61e2-6542-416e-aed6-43c481bbc12f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:18:07.898265Z",
          "iopub.status.busy": "2023-09-24T19:18:07.897759Z",
          "iopub.status.idle": "2023-09-24T19:18:08.588725Z",
          "shell.execute_reply": "2023-09-24T19:18:08.586967Z",
          "shell.execute_reply.started": "2023-09-24T19:18:07.898226Z"
        },
        "id": "c93b61e2-6542-416e-aed6-43c481bbc12f",
        "outputId": "c11d1710-d29b-4c92-f527-ca4854cdd87f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size (MB): 321.895469\n"
          ]
        }
      ],
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "\n",
        "print_size_of_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b524fd-c6ee-4852-9a98-6195ff033383",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T19:23:19.239880Z",
          "iopub.status.busy": "2023-09-24T19:23:19.239296Z",
          "iopub.status.idle": "2023-09-24T19:26:39.079874Z",
          "shell.execute_reply": "2023-09-24T19:26:39.078728Z",
          "shell.execute_reply.started": "2023-09-24T19:23:19.239831Z"
        },
        "id": "44b524fd-c6ee-4852-9a98-6195ff033383",
        "outputId": "7d5c85ae-40aa-4395-c57c-f199dd0ba99f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 / 1\n",
            "\n",
            "====================       INFERENCE - SPEED - RESULT       ====================\n",
            "--------------------------------------------------------------------------------\n",
            "          Model Name             Batch Size     Seq Length     Time in s   \n",
            "--------------------------------------------------------------------------------\n",
            "./pruned_models/pruned_V29613H       1               8             0.013     \n",
            "./pruned_models/pruned_V29613H       1              128            0.014     \n",
            "./pruned_models/pruned_V29613H       1              256            0.013     \n",
            "./pruned_models/pruned_V29613H       1              512            0.013     \n",
            "./pruned_models/pruned_V29613H       32              8             0.015     \n",
            "./pruned_models/pruned_V29613H       32             128             0.08     \n",
            "./pruned_models/pruned_V29613H       32             256             0.21     \n",
            "./pruned_models/pruned_V29613H       32             512            0.393     \n",
            "./pruned_models/pruned_V29613H       64              8             0.014     \n",
            "./pruned_models/pruned_V29613H       64             128            0.198     \n",
            "./pruned_models/pruned_V29613H       64             256            0.355     \n",
            "./pruned_models/pruned_V29613H       64             512            0.801     \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====================      INFERENCE - MEMORY - RESULT       ====================\n",
            "--------------------------------------------------------------------------------\n",
            "          Model Name             Batch Size     Seq Length    Memory in MB \n",
            "--------------------------------------------------------------------------------\n",
            "./pruned_models/pruned_V29613H       1               8              1161     \n",
            "./pruned_models/pruned_V29613H       1              128             1161     \n",
            "./pruned_models/pruned_V29613H       1              256             1161     \n",
            "./pruned_models/pruned_V29613H       1              512             1181     \n",
            "./pruned_models/pruned_V29613H       32              8              1183     \n",
            "./pruned_models/pruned_V29613H       32             128             1327     \n",
            "./pruned_models/pruned_V29613H       32             256             1567     \n",
            "./pruned_models/pruned_V29613H       32             512             2127     \n",
            "./pruned_models/pruned_V29613H       64              8              2127     \n",
            "./pruned_models/pruned_V29613H       64             128             2127     \n",
            "./pruned_models/pruned_V29613H       64             256             2127     \n",
            "./pruned_models/pruned_V29613H       64             512             3663     \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "benchmark_args = PyTorchBenchmarkArguments(\n",
        "    models=[MODEL_PATH],\n",
        "    training=False,\n",
        "    inference=True,\n",
        "    sequence_lengths=[8,128,256,512],\n",
        "    batch_sizes=[1,32,64],\n",
        "    multi_process=False,\n",
        "    cuda=True,\n",
        "    speed=True,\n",
        ")\n",
        "\n",
        "benchmark = PyTorchBenchmark(benchmark_args)\n",
        "results = benchmark.run()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- в качестве инструмента для прунинга была выбрана библиотека TextPruner - в ней реализован прунинг трансформеров-энкодеров.\n",
        "- убрали по 4 головы внимания из каждого слоя, было 12 - стало 8\n",
        "- уменьшили размерность ffn-слоев в полтора раза\n",
        "- существенно сократили словарь и матрицу эмбеддингов, оставив только те токены, которые хотя бы один раз встречаются в калибровочной выборке. Такой подход очень удобен, - если нужно адаптировать сетку под конкретный язык/домен\n",
        "\n",
        "Итог: скорость инференса возросла примерно в 2 раза, ROC AUC упал с ~96% до ~89%, размер сократился с 711 Мб до 322 Мб"
      ],
      "metadata": {
        "id": "1TSxyK6TC5mX"
      },
      "id": "1TSxyK6TC5mX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74d1b1c4-413c-4cba-aeb7-e2ea74c480d5",
      "metadata": {
        "id": "74d1b1c4-413c-4cba-aeb7-e2ea74c480d5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}