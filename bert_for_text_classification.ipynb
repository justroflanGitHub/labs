{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNtLJlW4v5VF"
      },
      "source": [
        "## Классификация текстов с использованием предобученных языковых моделей.\n",
        "\n",
        "В данном задании вам предстоит обратиться к задаче классификации текстов и решить ее с использованием предобученной модели BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3h0TCbMjF34",
        "outputId": "4ce8c76c-7b5f-488c-ec19-16ac59f12c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alGQayWSdLbB"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from IPython import display\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
        "\n",
        "import json\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from collections import Counter\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF99L5N7dLbB"
      },
      "source": [
        "Обратимся к набору данных SST-2. Holdout часть данных (которая понадобится вам для посылки) доступна по ссылке ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pRi3sOjdLbC",
        "outputId": "d0e54625-9c79-44af-c207-1764629d9b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-21 18:26:18--  https://raw.githubusercontent.com/girafe-ai/ml-course/refs/heads/24f_yandex_ml_trainings/homeworks/hw04_bert_and_co/texts_holdout.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51581 (50K) [text/plain]\n",
            "Saving to: ‘texts_holdout.json.2’\n",
            "\n",
            "\rtexts_holdout.json.   0%[                    ]       0  --.-KB/s               \rtexts_holdout.json. 100%[===================>]  50.37K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-04-21 18:26:18 (6.70 MB/s) - ‘texts_holdout.json.2’ saved [51581/51581]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/refs/heads/24f_yandex_ml_trainings/homeworks/hw04_bert_and_co/texts_holdout.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBf_qa_OdLbC"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv\",\n",
        "    delimiter=\"\\t\",\n",
        "    header=None,\n",
        ")\n",
        "texts_train = df[0].values[:5000]\n",
        "y_train = df[1].values[:5000]\n",
        "texts_test = df[0].values[5000:]\n",
        "y_test = df[1].values[5000:]\n",
        "with open(\"texts_holdout.json\") as iofile:\n",
        "    texts_holdout = json.load(iofile)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBOvEPmDdLbC"
      },
      "source": [
        "Весь остальной код предстоит написать вам.\n",
        "\n",
        "Для успешной сдачи на максимальный балл необходимо добиться хотя бы __84.5% accuracy на тестовой части выборки__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-YMO0AAeQck"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Oh6EYhCliAN"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQrOfv3KdLbC"
      },
      "outputs": [],
      "source": [
        "# 1. Загрузка предобученной модели BERT и токенизатора\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVSGNwT3kKLk"
      },
      "outputs": [],
      "source": [
        "# Создание датасета\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mXOE5-RaiXL"
      },
      "outputs": [],
      "source": [
        "# 3. Функция для получения эмбеддингов из BERT\n",
        "def get_bert_embeddings(texts, model, tokenizer, batch_size=64, max_length=256):\n",
        "    dataset = TextDataset(texts, tokenizer, max_length)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    embeddings = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Generating embeddings\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            # Используем [CLS] токен как представление всего текста\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(cls_embeddings)\n",
        "\n",
        "    return np.vstack(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmBVEtSsaiSA",
        "outputId": "b2d7ccae-e9ee-4072-ddf0-6e4971f33235"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings: 100%|██████████| 79/79 [01:16<00:00,  1.04it/s]\n",
            "Generating embeddings: 100%|██████████| 30/30 [00:28<00:00,  1.04it/s]\n",
            "Generating embeddings: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n"
          ]
        }
      ],
      "source": [
        "# 4. Получение эмбеддингов для train, test и holdout\n",
        "X_train_emb = get_bert_embeddings(texts_train, bert_model, tokenizer)\n",
        "X_test_emb = get_bert_embeddings(texts_test, bert_model, tokenizer)\n",
        "X_holdout_emb = get_bert_embeddings(texts_holdout, bert_model, tokenizer)\n",
        "\n",
        "# Преобразование в тензоры PyTorch\n",
        "X_train_emb_torch = torch.tensor(X_train_emb, dtype=torch.float32).to(device)\n",
        "X_test_emb_torch = torch.tensor(X_test_emb, dtype=torch.float32).to(device)\n",
        "X_holdout_emb_torch = torch.tensor(X_holdout_emb, dtype=torch.float32).to(device)\n",
        "\n",
        "y_train_torch = torch.tensor(y_train, dtype=torch.long).to(device)\n",
        "y_test_torch = torch.tensor(y_test, dtype=torch.long).to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBTiesYyaiL5"
      },
      "outputs": [],
      "source": [
        "# 5. Определение классификатора\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Размерность входных данных (размер эмбеддинга BERT)\n",
        "input_dim = X_train_emb.shape[1]\n",
        "hidden_dim = 256\n",
        "\n",
        "model = Classifier(input_dim, hidden_dim).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnDgvdQ-kRIc"
      },
      "outputs": [],
      "source": [
        "# 6. Оптимизатор и функция потерь\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQMwQj0rlW1W"
      },
      "outputs": [],
      "source": [
        "# 7. Функция обучения модели\n",
        "def train_model(model, opt, X_train, y_train, X_test, y_test, n_iterations=150):\n",
        "    for i in tqdm(range(n_iterations), desc=\"Training\"):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_train)\n",
        "        loss = loss_function(outputs, y_train)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        # Логирование каждые 100 итераций\n",
        "        if (i + 1) % 100 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                train_preds = torch.argmax(outputs, dim=1)\n",
        "                train_acc = accuracy_score(y_train.cpu(), train_preds.cpu())\n",
        "\n",
        "                test_outputs = model(X_test)\n",
        "                test_preds = torch.argmax(test_outputs, dim=1)\n",
        "                test_acc = accuracy_score(y_test.cpu(), test_preds.cpu())\n",
        "\n",
        "            print(f\"Iteration {i+1}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N-m6QdtlZp_",
        "outputId": "bdcdc552-4558-4e44-c9e0-d2f754457e22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 150/150 [00:00<00:00, 559.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 100: Train Acc = 0.9162, Test Acc = 0.8526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 8. Обучение модели\n",
        "model = train_model(model, opt, X_train_emb_torch, y_train_torch, X_test_emb_torch, y_test_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_DVoXF9lhZt"
      },
      "outputs": [],
      "source": [
        "# 9. Предсказания вероятностей\n",
        "def predict_proba(model, X):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X)\n",
        "        probs = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Вероятности класса 1\n",
        "    return probs\n",
        "\n",
        "train_probs = predict_proba(model, X_train_emb_torch)\n",
        "test_probs = predict_proba(model, X_test_emb_torch)\n",
        "holdout_probs = predict_proba(model, X_holdout_emb_torch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnlMBkORdLbC"
      },
      "source": [
        "#### Сдача взадания в контест\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba2a4CRQdLbC"
      },
      "outputs": [],
      "source": [
        "out_dict = {\n",
        "    'train': train_probs, # list of length 5000 with probas\n",
        "    'test': test_probs, # list of length 1920 with probas\n",
        "    'holdout': holdout_probs # list of length 500 with probas\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eajm3CodkVim"
      },
      "outputs": [],
      "source": [
        "# Преобразование в список, если это массив NumPy или тензор PyTorch\n",
        "if isinstance(out_dict[\"train\"], np.ndarray):\n",
        "    out_dict[\"train\"] = out_dict[\"train\"].tolist()\n",
        "elif isinstance(out_dict[\"train\"], torch.Tensor):\n",
        "    out_dict[\"train\"] = out_dict[\"train\"].cpu().numpy().tolist()\n",
        "\n",
        "# Преобразование всех элементов в float\n",
        "out_dict[\"train\"] = [float(x) for x in out_dict[\"train\"]]\n",
        "\n",
        "# Повторите аналогичные шаги для test и holdout\n",
        "if isinstance(out_dict[\"test\"], np.ndarray):\n",
        "    out_dict[\"test\"] = out_dict[\"test\"].tolist()\n",
        "elif isinstance(out_dict[\"test\"], torch.Tensor):\n",
        "    out_dict[\"test\"] = out_dict[\"test\"].cpu().numpy().tolist()\n",
        "out_dict[\"test\"] = [float(x) for x in out_dict[\"test\"]]\n",
        "\n",
        "if isinstance(out_dict[\"holdout\"], np.ndarray):\n",
        "    out_dict[\"holdout\"] = out_dict[\"holdout\"].tolist()\n",
        "elif isinstance(out_dict[\"holdout\"], torch.Tensor):\n",
        "    out_dict[\"holdout\"] = out_dict[\"holdout\"].cpu().numpy().tolist()\n",
        "out_dict[\"holdout\"] = [float(x) for x in out_dict[\"holdout\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaP9BhHIdLbC"
      },
      "source": [
        "Несколько `assert`'ов для проверки вашей посылки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOd7IUzOdLbC"
      },
      "outputs": [],
      "source": [
        "assert isinstance(out_dict[\"train\"], list), \"Object must be a list of floats\"\n",
        "assert isinstance(out_dict[\"train\"][0], float), \"Object must be a list of floats\"\n",
        "assert (\n",
        "    len(out_dict[\"train\"]) == 5000\n",
        "), \"The predicted probas list length does not match the train set size\"\n",
        "\n",
        "assert isinstance(out_dict[\"test\"], list), \"Object must be a list of floats\"\n",
        "assert isinstance(out_dict[\"test\"][0], float), \"Object must be a list of floats\"\n",
        "assert (\n",
        "    len(out_dict[\"test\"]) == 1920\n",
        "), \"The predicted probas list length does not match the test set size\"\n",
        "\n",
        "assert isinstance(out_dict[\"holdout\"], list), \"Object must be a list of floats\"\n",
        "assert isinstance(out_dict[\"holdout\"][0], float), \"Object must be a list of floats\"\n",
        "assert (\n",
        "    len(out_dict[\"holdout\"]) == 500\n",
        "), \"The predicted probas list length does not match the holdout set size\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzZtEmrcmOuM",
        "outputId": "8dfd7be9-dcda-4b8c-f99d-7437f4b82637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8458\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate Test Accuracy\n",
        "threshold = 0.5\n",
        "y_pred = [1 if p >= threshold else 0 for p in test_probs]\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hra5V9pfdLbD"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
